{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement: \n",
    "To undistort images obtained from camera (Camera Calibration) using OpenCV.\n",
    "\n",
    "## 2. Purpose: \n",
    "Today’s cheap pinhole cameras introduces a lot of distortion to images. Two major distortions are radial distortion and tangential distortion. Due to radial distortion, straight lines will appear curved. Its effect is more as we move away from the center of image.\n",
    "\n",
    "Important input data needed for camera calibration is a set of 3D real world points and its corresponding 2D image points\n",
    "3D points are called object points and 2D image points are called image points.\n",
    "\n",
    "**2D image points** can be easily found from the image. (eg. These image points are locations where two black squares touch each other in chess boards.)\n",
    "\n",
    "For obtaining **3D object points** images are taken from a static camera and chess boards are placed at different locations and orientations. So we need to know (X,Y,Z) values. But for simplicity, we can say chess board was kept stationary at XY plane, (so Z=0 always) and camera was moved accordingly. This consideration helps us to find only X,Y values. Now for X,Y values, we can simply pass the points as (0,0), (1,0), (2,0), ... which denotes the location of points. In this case, the results we get will be in the scale of size of chess board square. But if we know the square size, (say 30 mm), and we can pass the values as (0,0),(30,0),(60,0),..., we get the results in mm.\n",
    " \n",
    "Camera calibration is done given object points and image points using cv2.calibrateCamera() :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b24fb3c79e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result of chessboard calibration stored into a pickle file. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream is converted back into an object hierarchy. Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,” or “flattening”, however, to avoid confusion, the terms used here are “pickling” and “unpickling”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#Reading the stored calibration data from pickle file\n",
    "\n",
    "with open(\"camera_calibration_result.p\", mode='rb') as f:\n",
    "    camera_calib = pickle.load(f)\n",
    "\n",
    "mtx = camera_calib[\"mtx\"] #camera matrix \n",
    "dist = camera_calib[\"dist\"] #distortion coefficients\n",
    "\n",
    "\n",
    "\n",
    "#Reading image and converting BGR to RGB as imread() reads image as BGR\n",
    "\n",
    "img = cv2.imread(\"test_image.jpg\")\n",
    "imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "undistorted_img = cv2.undistort(imgRGB, mtx, dist, None, mtx)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Original Image')\n",
    "fig =plt.imshow(imgRGB)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Undistorted Image')\n",
    "fig =plt.imshow(undistorted_img )\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. References:\n",
    "1. https://docs.python.org/2/library/pickle.html\n",
    "2. docs.opencv.org/3.1.0/dc/dbb/tutorial_py_calibration.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
