{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Vehicle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future is basically the missing compatibilty layer betweeb python 2 and python 3. It allows use to use python 3.x codebase with minimal overhead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scikit-image is a Python package dedicated to image processing, and using natively NumPy arrays as image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This image module supports basic image loading, rescaling and display operations. This imports the module \"matplotlib.image\" and binds that to the name \"mpimg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This provides a MATLAB-like framework. This is very convenient for interactive work as mathematical plots can be easily done. This imports the module \"matplotlib.pyplot\" and binds that to the module \"plt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Numpy is a library for python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. It is the short form of numerical python package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OpenCV (Open Computer Vision) is a library of programming functions mainly aimed at real-timed computer vision. OpenCV has a modular structure, which means that the package includes several shared or static libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides various time-related functions. For related functionality, see also the datetime and calendar modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize a dataset along any axis.\n",
    "Center to the mean and component wise scale to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection and evaluation using tools, such as model_selection.GridSearchCV and model_selection.cross_val_score, take a scoring parameter that controls what metric they apply to the estimators evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle module implements a fundamental, but powerful algorithm for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream is converted back into an object hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image = mpimg.imread('test_images/test1.jpg')\n",
    "#return value of imread is numpy.array\n",
    "#define a function to compute a colour histogram\n",
    "#We need to change bin_range if reading .png file with mpimg\n",
    "def color_hist(image, nbins=32, bins_range=(0,256)):\n",
    "    #compute the histogram for RGB channels separately\n",
    "    rhist = np.histogram(image[:,:,0], bins = 32, range = (0,256))\n",
    "    ghist = np.histogram(image[:,:,1], bins = 32, range = (0,256))\n",
    "    bhist = np.histogram(image[:,:,2], bins = 32, range = (0,256))\n",
    "\n",
    "    #Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges)-1])/2\n",
    "\n",
    "    #Now we concatenate the histograms for R, G, B into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    #return rhist, ghist, bhist, bin_centers, hist_features\n",
    "    #We will only return the list of r,g,b channels\n",
    "    #print(\"Type of hist features:\",type(hist_features))\n",
    "    #print(\"Len of hist features: \", len(hist_features))\n",
    "    return hist_features\n",
    "\n",
    "#define a function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    #ravel() creates a flattened 1-D array\n",
    "    return features\n",
    "\n",
    "\n",
    "#define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient = 8, pix_per_cell = 8, cell_per_bock = 2, vis = True, feature_vec = True):\n",
    "    #If visualization is turned on ie vis == True, then return even the visualization. Else just return the features\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell,pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_bock,cell_per_bock),\n",
    "                                  visualise=vis, transform_sqrt=False,\n",
    "                                  feature_vector=feature_vec, normalise=None)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell = (pix_per_cell,pix_per_cell),\n",
    "                       cells_per_block=(cell_per_bock,cell_per_bock),\n",
    "                       visualise=vis, transform_sqrt=False,\n",
    "                       feature_vector=feature_vec, normalise=None)\n",
    "        return features\n",
    "\n",
    "#define a function to extract features from a list of images\n",
    "#This function will call bin_spatial() and color_hist()\n",
    "def extract_features(images, color_space = 'RGB', spatial_size = (32,32),\n",
    "                     hist_bins = 32, orient = 9,\n",
    "                     pix_per_cell = 8, cell_per_block = 2, hog_channel = 0,\n",
    "                     spatial_feat = True, hist_feat = True, hog_feat = True,\n",
    "                     viz = False, viz_only = False, hog_viz_name = \"\", viz_title = \"HOG Visualization\"):\n",
    "\n",
    "    #Create a list to append the feature vectors of all images\n",
    "    features = []\n",
    "    for file in images:\n",
    "        #File to store features of individual images\n",
    "        file_features = []\n",
    "        img = mpimg.imread(file)\n",
    "        #The value of img will be the dimensions width X height given as array. Type is numpy.ndarray\n",
    "        #print(\"The value of img on reading from the vector of image names: \", len(img))\n",
    "        #Apply color conversion if any\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            if color_space == 'LUV':\n",
    "                feature_image = cv2.cvtCcolor(img, cv2.COLOR_RGB2LUV)\n",
    "            if color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            if color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "            if color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(img)\n",
    "        #print(\"The values of feature image on applying a color conversion: \", feature_image)\n",
    "        #print(\"The value and type of feature image: \", len(feature_image), type(feature_image))\n",
    "        #Apply Spatial binning and color conversion\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        #print(\"The value of file_features after applying a spatial bin for 1 image : \",file_features, len(file_features[0]), type(file_features[0]))\n",
    "        #print(\"Length of file_features on appending spatial_features is: \", len(file_features))\n",
    "        #Apply color histogram\n",
    "        if hist_feat == True:\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            #print(\"The returned value of hist features is :\", hist_features)\n",
    "            #print(\"Length is: \", len(hist_features))\n",
    "            file_features.append(hist_features)\n",
    "        #print(\"Length of file_features on appending hist_features is: \", len(file_features))\n",
    "        #print(\"The value of file_features after applying hist_features is: \", file_features, file_features[1], type(file_features[1]))\n",
    "        #Call get_hog_features() with vis = False, feature_vec = True\n",
    "        if hog_feat == True:\n",
    "            if viz == True:\n",
    "                if hog_channel == 'ALL':\n",
    "                    hog_features = []\n",
    "                    #print(\"\\nFeature image.shape: \", feature_image.shape)\n",
    "                    for channel in range(feature_image.shape[2]):\n",
    "                        hog_feature, hog_image = get_hog_features(feature_image[:,:,channel],\n",
    "                                                                  orient, pix_per_cell, cell_per_block,\n",
    "                                                                  vis=True, feature_vec=True)\n",
    "                        hog_features.append(hog_feature)\n",
    "                    hog_features = np.ravel(hog_features)\n",
    "                    #print(\"The hog_features on setting channel as ALL are: \", hog_features, len(hog_features))\n",
    "\n",
    "                #If HOG channel is 0,1,2 ie R,G,B, then do the following function\n",
    "                else:\n",
    "                    hog_features, hog_image = get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                                               orient, pix_per_cell, cell_per_block,\n",
    "                                                               vis=True, feature_vec=True)\n",
    "                    print(\"The hog_features are: \", len(hog_features), type(hog_features))\n",
    "                    print(\"The hog_image: \", len(hog_image), type(hog_image))\n",
    "                #Plot HOG visualization\n",
    "                #Show only ther HOG image\n",
    "                if viz_only == True:\n",
    "                    fig = plt.figure()\n",
    "                    plt.imshow(hog_image)\n",
    "                    plt.title(viz_title)\n",
    "                    #plt.show()\n",
    "                    #plt.savefig(hog_viz_name, bbox_inches='tight')\n",
    "                #Show both the original and HOG image side by side for better comparison\n",
    "                else:\n",
    "                    fig = plt.figure()\n",
    "                    plt.subplot(121)\n",
    "                    plt.imshow(feature_image)\n",
    "                    plt.title('Sample image')\n",
    "                    plt.subplot(122)\n",
    "                    plt.imshow(hog_image)\n",
    "                    plt.title('Example HOG visualization')\n",
    "                    #plt.show()\n",
    "                    #plt.savefig(hog_viz_name + \"_double\", bbox_inches='tight')\n",
    "\n",
    "            #Now, if viz == False\n",
    "            #Same as the previous step, except that here we are not going to plot the images.\n",
    "            else:\n",
    "                if hog_channel == 'ALL':\n",
    "                    hog_features = []\n",
    "                    #print(\"\\nFeature image.shape: \", feature_image.shape)\n",
    "                    for channel in range(feature_image.shape[2]):\n",
    "                        hog_feature = get_hog_features(feature_image[:,:,channel],\n",
    "                                                       orient, pix_per_cell, cell_per_block,\n",
    "                                                       vis=False, feature_vec=True)\n",
    "                        hog_features.append(hog_feature)\n",
    "                    hog_features = np.ravel(hog_features)\n",
    "                    #print(\"The hog_features on setting channel as ALL are: \", hog_features, len(hog_features))\n",
    "                else:\n",
    "                    hog_features = get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                                    orient, pix_per_cell, cell_per_block,\n",
    "                                                    vis=False, feature_vec=True)\n",
    "\n",
    "            #Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "            #print(\"Length of file_featuers on appending hog_features : \", len(file_features))\n",
    "        features.append(np.concatenate(file_features))\n",
    "        #print(\"The length of the global features list, that contain the features of all the images read: \", len(features))\n",
    "    #Return the list of feature vectors\n",
    "    return features\n",
    "\n",
    "cars = glob.glob('vehicles/**/*.png', recursive = True)\n",
    "not_cars = glob.glob('non-vehicles/**/*.png', recursive = True)\n",
    "\n",
    "#Reduce the sample size\n",
    "sample_size = 10\n",
    "cars = cars[0:sample_size]\n",
    "not_cars = not_cars[0:sample_size]\n",
    "\n",
    "#select one car by index randomly\n",
    "sample_car = [cars[5]]\n",
    "sample_not_car = [not_cars[5]]\n",
    "print(sample_car)\n",
    "\n",
    "#call the funtion on the image/images\n",
    "car_features = extract_features(sample_car, viz=True, hog_channel='ALL')\n",
    "not_car_features = extract_features(sample_not_car, viz=True, hog_channel='ALL')\n",
    "\n",
    "print(len(car_features))\n",
    "print(len(not_car_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set parameters used to call extract features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "color_space = \"RGB\"\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_size = (32,32)\n",
    "hist_bins = 32\n",
    "spatial_feat = True\n",
    "hist_feat = True\n",
    "hog_feat = True\n",
    "\n",
    "def color_hist(image, nbins=32, bins_range=(0,256)):\n",
    "    #compute the histogram for RGB channels separately\n",
    "    rhist = np.histogram(image[:,:,0], bins = 32, range = (0,256))\n",
    "    ghist = np.histogram(image[:,:,1], bins = 32, range = (0,256))\n",
    "    bhist = np.histogram(image[:,:,2], bins = 32, range = (0,256))\n",
    "\n",
    "    #Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges)-1])/2\n",
    "\n",
    "    #Now we concatenate the histograms for R, G, B into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    return hist_features\n",
    "\n",
    "#define a function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    #ravel() creates a flattened 1-D array\n",
    "    return features\n",
    "\n",
    "\n",
    "#define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient = 8, pix_per_cell = 8, cell_per_bock = 2, vis = True, feature_vec = True):\n",
    "    #If visualization is turned on ie vis == True, then return even the visualization. Else just return the features\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell,pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_bock,cell_per_bock),\n",
    "                                  visualise=vis, transform_sqrt=False,\n",
    "                                  feature_vector=feature_vec, normalise=None)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(img, orientations=orient,\n",
    "                       pixels_per_cell = (pix_per_cell,pix_per_cell),\n",
    "                       cells_per_block=(cell_per_bock,cell_per_bock),\n",
    "                       visualise=vis, transform_sqrt=False,\n",
    "                       feature_vector=feature_vec, normalise=None)\n",
    "        return features\n",
    "\n",
    "#define a function to extract features from a list of images\n",
    "def extract_features(images, color_space = 'RGB', spatial_size = (32,32),\n",
    "                     hist_bins = 32, orient = 9,\n",
    "                     pix_per_cell = 8, cell_per_block = 2, hog_channel = 0,\n",
    "                     spatial_feat = True, hist_feat = True, hog_feat = True,\n",
    "                     viz = False, viz_only = False, hog_viz_name = \"\", viz_title = \"HOG Visualization\"):\n",
    "\n",
    "    features = []\n",
    "    for file in images:\n",
    "        #File to store features of individual images\n",
    "        file_features = []\n",
    "        img = mpimg.imread(file)\n",
    "        #The value of img will be the dimensions width X height given as array. Type is numpy.ndarray\n",
    "\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            if color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            if color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            if color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "            if color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else:\n",
    "            feature_image = np.copy(img)\n",
    "\n",
    "        #Apply Spatial binning and color conversion\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        #Apply color histogram\n",
    "        if hist_feat == True:\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            #print(\"The returned value of hist features is :\", hist_features)\n",
    "            #print(\"Length is: \", len(hist_features))\n",
    "            file_features.append(hist_features)\n",
    "        #Call get_hog_features() with vis = False, feature_vec = True\n",
    "        if hog_feat == True:\n",
    "            if viz == True:\n",
    "                if hog_channel == 'ALL':\n",
    "                    hog_features = []\n",
    "                    for channel in range(feature_image.shape[2]):\n",
    "                        hog_feature, hog_image = get_hog_features(feature_image[:,:,channel],\n",
    "                                                                  orient, pix_per_cell, cell_per_block,\n",
    "                                                                  vis=True, feature_vec=True)\n",
    "                        hog_features.append(hog_feature)\n",
    "                    hog_features = np.ravel(hog_features)\n",
    "\n",
    "                else:\n",
    "                    hog_features, hog_image = get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                                               orient, pix_per_cell, cell_per_block,\n",
    "                                                               vis=True, feature_vec=True)\n",
    "                    print(\"The hog_features are: \", len(hog_features), type(hog_features))\n",
    "                    print(\"The hog_image: \", len(hog_image), type(hog_image))\n",
    "                #Plot HOG visualization\n",
    "                #Show only ther HOG image\n",
    "                if viz_only == True:\n",
    "                    fig = plt.figure()\n",
    "                    plt.imshow(hog_image)\n",
    "                    plt.title(viz_title)\n",
    "                    #plt.show()\n",
    "                    #plt.savefig(hog_viz_name, bbox_inches='tight')\n",
    "                #Show both the original and HOG image side by side for better comparison\n",
    "                else:\n",
    "                    fig = plt.figure()\n",
    "                    plt.subplot(121)\n",
    "                    plt.imshow(feature_image)\n",
    "                    plt.title('Sample image')\n",
    "                    plt.subplot(122)\n",
    "                    plt.imshow(hog_image)\n",
    "                    plt.title('Example HOG visualization')\n",
    "                    #plt.show()\n",
    "                    #plt.savefig(hog_viz_name + \"_double\", bbox_inches='tight')\n",
    "\n",
    "            #Now, if viz == False\n",
    "            #Same as the previous step, except that here we are not going to plot the images.\n",
    "            else:\n",
    "                if hog_channel == 'ALL':\n",
    "                    hog_features = []\n",
    "                    for channel in range(feature_image.shape[2]):\n",
    "                        hog_feature = get_hog_features(feature_image[:,:,channel],\n",
    "                                                       orient, pix_per_cell, cell_per_block,\n",
    "                                                       vis=False, feature_vec=True)\n",
    "                        hog_features.append(hog_feature)\n",
    "                    hog_features = np.ravel(hog_features)\n",
    "                else:\n",
    "                    hog_features = get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                                    orient, pix_per_cell, cell_per_block,\n",
    "                                                    vis=False, feature_vec=True)\n",
    "\n",
    "            #Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "            #print(\"Length of file_featuers on appending hog_features : \", len(file_features))\n",
    "        features.append(np.concatenate(file_features))\n",
    "    #Return the list of feature vectors\n",
    "    return features\n",
    "\n",
    "cars = glob.glob('vehicles/**/*.png', recursive = True)\n",
    "not_cars = glob.glob('non-vehicles/**/*.png', recursive = True)\n",
    "\n",
    "#Reduce the sample size\n",
    "#sample_size = 5\n",
    "#cars = cars[0:sample_size]\n",
    "#not_cars = not_cars[0:sample_size]\n",
    "\n",
    "#call the funtion on the image/images\n",
    "car_features = extract_features(cars, color_space=color_space,\n",
    "                                spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel='ALL', spatial_feat=spatial_feat,\n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat,\n",
    "                                viz=False)\n",
    "not_car_features = extract_features(not_cars, color_space=color_space,\n",
    "                                spatial_size=spatial_size,\n",
    "                                hist_bins=hist_bins, orient=orient,\n",
    "                                pix_per_cell=pix_per_cell,\n",
    "                                cell_per_block=cell_per_block,\n",
    "                                hog_channel='ALL', spatial_feat=spatial_feat,\n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat,\n",
    "                                viz=False)\n",
    "\n",
    "#Type of x is numpy.ndarray\n",
    "#it will have the length = 10 cars + 10 not-cars = 20\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "#print(X)\n",
    "#print(type(X))\n",
    "#print(len(X))\n",
    "\n",
    "#fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "#print(X_scaler)         #Output: StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#print(type(X_scaler))   #Output: <class 'sklearn.preprocessing.data.StandardScaler'>\n",
    "\n",
    "#Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "#print(scaled_X)\n",
    "#print(type(scaled_X))   #numpy.ndarray\n",
    "#print(len(scaled_X))    # 20 for 10 + 10 examples\n",
    "#Scaled_X is the array that contains the featuers of individual images and the next list Y, contains the assciated class values\n",
    "#ie car or not car. Thus, we are assigning the Y array to those many 1's as there are cars and 0's for not cars\n",
    "#Define the labels vector\n",
    "Y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "#print(Y)            #[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.   0.  0.]\n",
    "#print(len(Y))       #len 20\n",
    "#print(type(Y))      #numpy.ndarray\n",
    "\n",
    "#Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0,100)\n",
    "#print(rand_state)\n",
    "#Randomly assigns a number to rand_state from 0 to 99. This value changes with every new function call\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_X, Y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "#print(x_train)\n",
    "#print(len(x_train))\n",
    "#print(x_test)\n",
    "#print(len(x_test))\n",
    "\n",
    "#print(y_train)\n",
    "#print(len(y_train))\n",
    "#print(y_test)\n",
    "#print(len(y_test))\n",
    "\n",
    "#print('Feature vector length : ', len(x_train[0]))\n",
    "\n",
    "#Use a linear SVC\n",
    "svc = LinearSVC()\n",
    "\n",
    "#Check the training time for SVC\n",
    "t1 = time.time()\n",
    "svc.fit(x_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t1, 2), ' seconds were required for training the SVC')\n",
    "\n",
    "#Check the score of the SVC\n",
    "#print(\"Total number of car samples: \", len(cars))\n",
    "#print(\"Total number of not_car samples: \", len(not_cars))\n",
    "print('Test accuracy for SVC = ', round(svc.score(x_test, y_test), 4))\n",
    "\n",
    "\"\"\"\n",
    "Applying SVM on all the available data, result:\n",
    "\n",
    "Feature vector length :  8460\n",
    "28.18  seconds were required for training the SVC\n",
    "Total number of car samples:  8792\n",
    "Total number of not_car samples:  8968\n",
    "Test accuracy for SVC =  0.9811\n",
    "\"\"\"\n",
    "\n",
    "#Compare results:\n",
    "n_predict = 15\n",
    "#print(\"Values predicted by SVC = \", svc.predict((x_test[0:n_predict])))\n",
    "#print(\"Actual labels =           \", y_test[0:n_predict])\n",
    "\n",
    "\"\"\"\n",
    "1st call:\n",
    "Values predicted by SVC =  [ 0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.  1.]\n",
    "Actual labels =            [ 0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.  1.]\n",
    "\n",
    "2nd call:\n",
    "Values predicted by SVC =  [ 0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.]\n",
    "Actual labels =            [ 0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.]\n",
    "\"\"\"\n",
    "\n",
    "model_pickle = {}\n",
    "#print(type(model_pickle))   #model_pickle is of type dict and hence stores values as key-value pairs\n",
    "\n",
    "model_pickle['svc'] = svc\n",
    "model_pickle['scaler'] = X_scaler\n",
    "model_pickle['orient'] = orient\n",
    "model_pickle['pix_per_cell'] = pix_per_cell\n",
    "model_pickle['cell_per_block'] = cell_per_block\n",
    "model_pickle['spatial_size'] = spatial_size\n",
    "model_pickle['hist_bins'] = hist_bins\n",
    "pickle.dump(model_pickle, open(\"linearSVM training.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#implement a sliding window and use your trained classifier to search for vehicles in images\n",
    "#The function takes an image, start and stop positions in both x and y, window size(x and y dimensions),\n",
    "#and overlap fraction (for both x and y)\n",
    "#Default xy_window is 64 X 64 and there is 50% overlap\n",
    "def slide_window(img, x_start_stop = [None, None], y_start_stop = [None, None],\n",
    "                 xy_window = (64,64), xy_overlap = (0.5,0.5)):\n",
    "\n",
    "    \"\"\"\n",
    "    print(x_start_stop)\n",
    "    print(y_start_stop)\n",
    "\n",
    "    If we call the function plainly without providing the x_start_stop and y_start_stop, then the output is:\n",
    "    [None, None]\n",
    "    [None, None]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #if x and/or y start/stop positions are not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "\n",
    "    \"\"\"\n",
    "    It will be list as the default args is [None, None]\n",
    "    print(x_start_stop)\n",
    "    print(type(x_start_stop))\n",
    "    \n",
    "    Output:\n",
    "    [0, 1280]\n",
    "    <class 'list'>\n",
    "    ------------------------\n",
    "    print(y_start_stop)\n",
    "    print(type(y_start_stop))\n",
    "    \n",
    "    Output:\n",
    "    [0, 720]\n",
    "    <class 'list'>\n",
    "    \"\"\"\n",
    "\n",
    "    #Compute the span of the region to be searched\n",
    "    x_span = x_start_stop[1] - x_start_stop[0]\n",
    "    y_span = y_start_stop[1] - y_start_stop[0]\n",
    "\n",
    "    #here we can select how much region of our image we want to scan. As the car can be in any region, and not any sepcific\n",
    "    #part, we will scan the entire image.\n",
    "    #print(x_span)  #Output: 1280 and type is int\n",
    "    #print(y_span)  #Output: 720  and type is int\n",
    "\n",
    "    #Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0] * (1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1] * (1 - xy_overlap[1]))\n",
    "\n",
    "    \"\"\"\n",
    "    This is the size of the window leaving the overlapped part, eg the four corners\n",
    "    print(nx_pix_per_step)\n",
    "    print(type(nx_pix_per_step))\n",
    "\n",
    "    Output:\n",
    "    160\n",
    "    <class 'int'>\n",
    "    \n",
    "    print(ny_pix_per_step)\n",
    "    print(type(ny_pix_per_step))\n",
    "    \n",
    "    Output:\n",
    "    160\n",
    "    <class 'int'>\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0] * xy_overlap[0])\n",
    "    ny_buffer = np.int(xy_window[1] * xy_overlap[1])\n",
    "    nx_windows = np.int((x_span - nx_buffer) / nx_pix_per_step)\n",
    "    # ie 1280 - 40 == 1240. 1240 / 160 == 7\n",
    "    ny_windows = np.int((y_span - ny_buffer) / ny_pix_per_step)\n",
    "    #ie 720 - 40 == 680. 680 / 160 == 4\n",
    "    \"\"\" \n",
    "    Here, it shows how many pixels are overlapped, ie 200 - 160 = 40 as 20% of 200 is 40\n",
    "    print(nx_buffer)\n",
    "    print(ny_buffer)  \n",
    "    \n",
    "    Output:\n",
    "    40\n",
    "    40\n",
    "\n",
    "    print(nx_windows)\n",
    "    print(ny_windows)\n",
    "\n",
    "    Output:\n",
    "    7\n",
    "    4\n",
    "    \"\"\"\n",
    "    #Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "\n",
    "    #Loop through finding x and y window positions\n",
    "    #Note: You could vectorize this step, but in practice you'll be considering windows\n",
    "    #one by one with your classifier, so looping makes sense\n",
    "\n",
    "    #ys goes form 0 to 3 ie 4 vertical windows\n",
    "    #xs goes form 0 to 6 ie 7 horizontal windows\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "\n",
    "            #Calculate window position\n",
    "            startx = xs * nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            # Eg: xs = 0. Therefore, 0 * 160 + 0 = 0\n",
    "            # Eg: xs = 1. Therefore, 1 * 160 + 0 = 160\n",
    "            # Eg: xs = 2. Therefore, 2 * 160 + 0 = 320, etc\n",
    "            #add 200 to the value of startx as our window is 200 X 200\n",
    "            #Thus draw boxes with x co-ordinates as 0 to 200, 160 to 360, 320 to 520 and so on\n",
    "\n",
    "            #Sample output of 3 boxes: [((0, 0), (200, 200)), ((160, 0), (360, 200)), ((320, 0), (520, 200)),......\n",
    "            starty = ys * ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            #add 200 to the value of starty as out window is 200 X 200\n",
    "\n",
    "            #Append window position to list\n",
    "            #Add these co-ordinates to the window_list and this list will be used by draw_boxes funtion to draw the boxes\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    print(window_list)\n",
    "    #Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "image = mpimg.imread('test5.jpg')\n",
    "#Given image is of the dimensions 1280 X 720\n",
    "\n",
    "# #Define a function to draw bounding boxes\n",
    "#It takes as input an image, a list of bounding boxes and an optional color tuple and line thickness\n",
    "#as inputs and then draws boxes in that color on the output\n",
    "\n",
    "def draw_boxes(img, bboxes, color = (0,0,255), thick = 6):\n",
    "    #make a copy of the image and then draw on it\n",
    "    imcopy = np.copy(img)\n",
    "    #Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        #Draw a rectangle given bbox co-ordinates\n",
    "        #Write a text above the window to indicate the type of object detected\n",
    "        #print(bbox[0][0], bbox[1][1]) will print the value of the left top coordinates of the box\n",
    "        #We print the text 'vehicle' of white color on top of every window and also draw the rectange of blue color.\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        #cv2.putText(imcopy, 'vehicle', (bbox[0][0], bbox[1][1]), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "\n",
    "    #return the image copy with the boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "w_list = slide_window(image, xy_window=(200,200), xy_overlap=(0.2,0.2))\n",
    "result = draw_boxes(image, w_list)\n",
    "\n",
    "#Here we simply display the output\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(result)\n",
    "plt.title('Image with 200 X 200 window and 20% overlap (normal case)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
